背景：一个io操作需要经过两个阶段，一个是等待阶段，等待连接、等待数据到内核等，第二个是讲数据拷贝到用户空间

编程模型种类：
  单线程、多线程、事件驱动

用户空间和内核空间：
  操作系统把虚拟内存分的空间，内核都可以访问，一般进程只能访问用户空间

文件描述符fd
  内核为每一个进程所维护的该进程打开文件的记录表，一个索引key

io缓存
  用户空间没法直接访问内核空间，内核态到用户态的数据拷贝，先放内核空间再一次性拷贝到用户空间

事件驱动模型：
  向事件队列里面写，线程循环读出并回调

io模型
1) 同步阻塞IO（Blocking IO）
   阻塞的等着io
   当进程进入阻塞状态时是不占用CPU资源的
2) 同步非阻塞IO（Non-blocking IO）
  不阻塞但会一直循环io是否准备好，占用很多cpu
  阻塞是两个阶段都在block,非阻塞是线程会一直询问
3) IO多路复用（IO Multiplexing）
  select用于一个线程监听多个io的执行（fd是否可读写完）， 等到数据到达时通知用户线程，则可以提高用户线程的CPU利用率.
  poll： 线性轮询的处理机制
  epoll： 回调callback的处理机制

  select的几大缺点：
（1）每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大
（2）同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大
（3）select支持的文件描述符数量太小了，默认是1024

   epoll解决是提供3个函数epoll_create,epoll_ctl和epoll_wait.1.每个fd从用户态拷贝到内核只一次
                  2.为每个fd注册一个事件，当事件发生后保存到链表，而 epoll_wait只循环这个链表
                  3.fd的数量提高了

4) 异步IO（Asynchronous IO）
  马上收到io通知，目前操作系统对异步IO的支持并不完善
